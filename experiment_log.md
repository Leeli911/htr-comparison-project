# HTRFlow 实验日志

**项目**: HTRFlow vs Loghi 性能对比研究  
**研究者**: Li Li  
**开始日期**: 2025-10-19

---

## 实验 #000 - 项目立项

**日期**: 2025-10-19  
**目标**: 建立完整的项目环境和文档体系

### 环境配置

**系统信息**:
- macOS (Apple Silicon/Intel)
- Python 3.11.11
- PyTorch 2.2.2

**虚拟环境**:
- 名称: htrflow_env
- 位置: ~/htrflow_env/

**已安装包**:
```
torch==2.2.2
torchvision==0.17.2
torchaudio==2.2.2
htrflow (已安装)
```

### 项目结构
```
htr-comparison-project/
├── configs/htrflow/pipeline.yaml
├── data/{raw,samples,ground_truth}/
├── outputs/{htrflow,loghi,batch,figures}/
├── scripts/
├── docs/
├── screenshots/
├── notebooks/
├── reports/
├── README.md
├── requirements.txt
├── .gitignore
├── progress_tracker.md
└── experiment_log.md
```

### Git 仓库

- 初始化: ✅
- 首次提交: ✅
- 分支: master/main

### 结论

✅ 项目立项完成  
✅ 开发环境就绪  
✅ 准备进行第一次识别测试

### 下一步

1. 下载测试图片到 data/samples/
2. 运行 HTRFlow pipeline
3. 验证输出结果

---

[后续实验记录将在这里添加]

---

**最后更新**: 2025-10-19

## 实验 #001 - 第一次文本识别

**日期**: 2025-10-19  
**时间**: 20:12-20:29 (17分钟)  
**目标**: 验证 HTRFlow 能成功识别瑞典历史手写文档

### 实验设置
- **配置文件**: `configs/htrflow/pipeline.yaml`
- **测试图片**: `data/samples/test.jpg` (752KB)
- **图片来源**: 瑞典历史文档 (1613年)
- **处理设备**: CPU (macOS)

### Pipeline 步骤

1. **Segmentation (YOLO)**
   - 模型: `Riksarkivet/yolov9-lines-within-regions-1`
   - 模型大小: 122MB
   - 处理时间: ~3秒
   - 检测文本行: 33行

2. **TextRecognition (TrOCR)**
   - 模型: `Riksarkivet/trocr-base-handwritten-hist-swe-2`
   - 模型大小: 1.54GB
   - 处理时间: 约16分钟 (平均 30秒/行)
   - 批量大小: 1 (CPU限制)

3. **OrderLines**
   - 快速完成

4. **Export**
   - 输出格式: TXT
   - 输出位置: `outputs/htrflow/samples/test.txt`

### 实验结果

**性能数据**:
- 总处理时间: **1032秒** (约17分钟)
- 文本行数: 33行
- 平均速度: 30秒/行
- 识别文本长度: ~1800字符

**识别文本样本**:
```
Em wy Christinas medh Guds nåde, Sweriges, Göthes Wänder, Finnars
Karlers Lappgers i Norrlanden ähr Kryarnas och Eders i Lifland...
[完整内容见 outputs/htrflow/samples/test.txt]
```

**文档类型**: 1613年瑞典皇家文件（关于 Älvsborg 赎金）

### 观察与分析

**识别质量** (目测评估):
- ✅ 整体识别质量: 良好
- ✅ 瑞典语特殊字符 (å, ä, ö): 正确识别
- ✅ 17世纪拼写变体: 大部分正确
- ⚠️ 个别连写字母可能有误

**版面分析**:
- ✅ 成功检测所有33行文本
- ✅ 行序正确排列
- ✅ 无漏检

**CPU性能**:
- ⏱️ 单页处理约17分钟（CPU）
- 📝 预计 GPU 可提速 10-20倍
- ✅ 对于测试和研究足够

### 遇到的问题

#### 问题 #1: NumPy 版本冲突
- **现象**: `RuntimeError: Numpy is not available`
- **原因**: NumPy 2.2.6 与 PyTorch 2.2.2 不兼容
- **解决**: `pip install "numpy<2.0" --force-reinstall`
- **用时**: 5分钟

#### 问题 #2: 首次运行模型下载
- **现象**: 下载 1.54GB TrOCR 模型需要时间
- **用时**: ~65秒
- **备注**: 后续运行会使用缓存，无需重新下载

### 结论

✅ **HTRFlow 在 CPU 上成功运行**  
✅ **识别质量符合预期**  
✅ **适合瑞典历史文档识别**

### 下一步

- [ ] 测试 JSON 输出格式
- [ ] 对比不同 beam search 参数
- [ ] 准备更多测试图片
- [ ] 记录性能基准数据

### 截图

- 终端输出: `screenshots/20251019_first_run_terminal.png`
- 识别结果: `screenshots/20251019_first_run_output.png`

---
## 实验 #002 - JSON 输出格式测试

**日期**: 2025-10-21  
**时间**: 19:05-19:17 (12分钟)  
**目标**: 测试 HTRFlow 的 JSON 输出格式，对比与 TXT 的差异

### 实验设置
- **配置**: `configs/htrflow/pipeline_json.yaml`
- **测试图片**: `data/samples/test.jpg` (与实验#001相同)
- **主要变更**: Export format: txt → json

### 性能对比

| 指标 | 实验#001 (TXT) | 实验#002 (JSON) | 变化 |
|------|----------------|-----------------|------|
| 处理时间 | 1032秒 | 741秒 | ⬇️ 快了29% |
| 输出文件 | test.txt | test.json | - |
| 检测行数 | 33行 | 33行 | ✅ 一致 |

**处理加速原因**:
- ✅ 模型已缓存，无需下载
- ✅ 系统资源优化

### JSON 结构分析

**新增信息类型**:

1. **置信度分数** (每行的识别可信度)
   - 示例: `"scores": [0.9877935...]`
   - 范围: 0-1，越高越可信
   - 用途: 筛选低质量识别结果

2. **边界框坐标** (每行文本的位置)
   - 格式: `{"xmin": X, "ymin": Y, "xmax": X, "ymax": Y}`
   - 用途: 定位文本在原图中的位置

3. **精确多边形**
   - 格式: `"polygon": "x1,y1 x2,y2 ..."`
   - 用途: 不规则文本行的精确边界

4. **处理步骤追踪**
   - 记录使用的模型和版本
   - 用途: 实验可重现性

### 置信度分析

**Top 5 最高置信度**:
```
Line 15: 0.9978 - "Ständers bewilning och samptyckie..."
Line 25: 0.9978 - "Wermeland, Waßbo och Wälla..."
Line 8:  0.9977 - "sidher förstå huruledes..."
Line 26: 0.9971 - "gunsteligen och nådeligen..."
Line 12: 0.9976 - "fyllest betalt. Huarföre..."
```

**最低置信度**:
```
Line 3 (No 7): 0.1396 ⚠️ - 可能是标注或页码
```

### TXT vs JSON 对比

| 方面 | TXT 格式 | JSON 格式 | 最佳应用 |
|------|----------|----------|----------|
| **可读性** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | TXT 更易阅读 |
| **信息量** | ⭐⭐ | ⭐⭐⭐⭐⭐ | JSON 信息丰富 |
| **程序处理** | ⭐⭐ | ⭐⭐⭐⭐⭐ | JSON 易于解析 |
| **文件大小** | 小 | 大 (~10倍) | TXT 更紧凑 |
| **质量分析** | ❌ 不支持 | ✅ 支持 | JSON 可筛选 |
| **位置信息** | ❌ 无 | ✅ 有 | JSON 可可视化 |

### 使用建议

**使用 TXT 的场景**:
- ✅ 人工快速查看识别结果
- ✅ 简单的文本存档
- ✅ 文件大小敏感的情况

**使用 JSON 的场景**:
- ✅ 自动化评估 (计算 WER/CER)
- ✅ 质量筛选 (根据置信度过滤)
- ✅ 可视化展示 (绘制边界框)
- ✅ 进一步数据分析
- ✅ **研究和对比实验** ← 我们的情况

### 结论

✅ JSON 格式更适合本研究项目，因为：
1. 包含置信度，便于质量评估
2. 包含坐标，便于错误分析
3. 结构化数据，便于与 Loghi 对比
4. 可追溯处理步骤

**建议**: 后续实验统一使用 JSON 格式输出

### 截图
- JSON 输出样本: `screenshots/day2/20251021_second_run_output.png`
- JSON 跑数记录：`screenshots/day2/20251021_second_run_terminal.png`

---

## 实验 #003 - Beam Search 参数优化完整对比

**日期**: 2025-10-22  
**时间**: 22:02-22:56 (54分钟)  
**目标**: 找到 HTRFlow 的最佳 num_beams 配置（验证 H3）

### 实验设置

**测试参数**: num_beams = [1, 2, 4, 8]  
**测试数据**: data/samples/test.jpg (2776×4136, 33行文本)  
**其他配置**: 保持不变  
**硬件**: macOS CPU

### 完整实验数据

| num_beams | 处理时间 | 平均置信度 | 最高置信度 | 最低置信度 | 低质量行(<0.90) | 质量评级 |
|-----------|----------|------------|------------|------------|-----------------|----------|
| 1         | 329s (5.5min) | 0.8289 | 0.9731 | 0.6462 | 21/33 (64%) | ❌ 较差 |
| 2         | 546s (9.1min) | **0.9882** | **0.9991** | 0.8645 | **1/33 (3%)** | ✅ 优秀 |
| 4         | 857s (14.3min) | 0.9617 | 0.9979 | 0.1397 | 2/33 (6%) | ✅ 良好 |
| 8         | 1483s (24.7min) | **0.9882** | 0.9985 | 0.8645 | **1/33 (3%)** | ✅ 优秀 |

### 速度与质量权衡分析

#### 速度对比（以 beam=1 为基线）
```
Beam=1: 329s (100%) ████░░░░░░ 基线速度
Beam=2: 546s (166%) ████████░░ +66% 时间
Beam=4: 857s (260%) ████████████░░ +160% 时间
Beam=8: 1483s (451%) ████████████████████ +351% 时间
```

#### 质量提升曲线
```
Beam=1 → Beam=2: 质量跃升 19% ⬆️⬆️⬆️
Beam=2 → Beam=4: 质量下降 3% ⬇️
Beam=4 → Beam=8: 质量提升 3% ⬆️
```

### 关键发现

#### 🌟 发现 1: Beam=2 是最佳配置！

**意外的最优点**：
- 原假设：beam=4 是最佳平衡点
- **实际结果**：beam=2 表现最优！

**数据支持**：
```
Beam=2 vs Beam=4:
✅ 置信度更高: 0.9882 > 0.9617 (+2.7%)
✅ 速度更快: 546s < 857s (快 36%)
✅ 低质量行更少: 1行 < 2行

Beam=2 vs Beam=8:
✅ 置信度相同: 0.9882 = 0.9882
✅ 速度快得多: 546s << 1483s (快 63%!)
✅ 低质量行相同: 1行 = 1行
```

**结论**: **Beam=2 在质量和速度上都达到最优平衡**

---

#### 发现 2: Beam=1 严重不足

**质量问题**：
- 平均置信度: 0.8289 (低于 0.90 阈值)
- 64% 的文本行质量不合格
- 最低置信度: 0.6462 (非常不可靠)

**示例错误**：
```
Ground Truth: "Christina"
Beam=1: "Christimam" ❌

Ground Truth: "Vttekohradhe"
Beam=1: "Vttekohöherdhe" ❌
```

---

#### 发现 3: Beam=4 的异常低点

**奇怪的现象**：
- Beam=4 的置信度 (0.9617) 低于 Beam=2 (0.9882)
- 这违反了"beam越大质量越好"的常识

**可能原因**：
1. 随机性因素（beam search 有概率成分）
2. 特定文本对 beam=2 更友好
3. 模型架构特性

**需要验证**：
- 在更多图片上重复实验
- 确认这是否是普遍规律

---

#### 发现 4: Beam=8 的低效率

**投入产出比**：
- 比 Beam=2 慢 172%
- 质量提升: 0% (完全相同)
- **结论**: 不值得使用

---

### 假设验证

#### ✅ H3 部分支持

**原假设**：
> "增加 num_beams 会提高识别准确率，但会降低处理速度"

**验证结果**：
```
✅ 速度预测正确:
   beam ↑ → 时间 ↑ (线性增长)

⚠️  质量预测部分正确:
   beam: 1→2, 质量大幅提升 ✅
   beam: 2→4, 质量反而下降 ❌
   beam: 4→8, 质量小幅提升 ✅
```

**修正后的结论**：
> "num_beams=2 达到质量峰值，进一步增加 beam 不能显著提升质量，反而大幅降低速度"

---

### 实践建议

#### 🎯 推荐配置

**场景 1: 大规模处理（推荐）**
```yaml
generation_settings:
  num_beams: 2  # ⭐ 最佳选择
```
- **理由**: 质量最优，速度尚可
- **适用**: Gender and Work 项目 (1000+ 页)
- **预计时间**: 9分钟/页 × 1000页 = 150小时 (约 6 天)

**场景 2: 快速预览**
```yaml
generation_settings:
  num_beams: 1
```
- **理由**: 速度最快
- **适用**: 快速检查文档质量
- **注意**: 质量不保证，仅用于筛选

**场景 3: 极高质量需求**
```yaml
generation_settings:
  num_beams: 2  # 仍然推荐 2，不是 8！
```
- **理由**: beam=2 和 beam=8 质量相同
- **不推荐 beam=8**: 浪费时间，无额外收益

---

### GPU 预估

基于当前 CPU 结果，预估 GPU 性能：

| 配置 | CPU时间 | GPU时间(预估) | GPU加速比 |
|------|---------|---------------|-----------|
| Beam=1 | 329s | ~20-30s | 10-15x |
| Beam=2 | 546s | ~30-50s | 10-15x |
| Beam=4 | 857s | ~50-80s | 10-15x |
| Beam=8 | 1483s | ~90-150s | 10-15x |

**大规模处理预估**（50张图片）：
```
CPU (Beam=2): 546s × 50 = 27,300s ≈ 7.6小时
GPU (Beam=2): 40s × 50 = 2,000s ≈ 33分钟 ✨
```

---

### 下一步行动

#### 立即 (Week 2):
1. ✅ 更新所有 pipeline 配置为 num_beams=2
2. ✅ 准备向导师汇报这个发现
3. ✅ 准备 20-50 张测试图片

#### Week 3 (GPU 阶段):
1. 用 beam=2 配置进行大规模测试
2. 验证这个结论在多图片上是否一致
3. 与 Loghi 对比（也用最优配置）

#### Week 5-6 (迁移学习):
1. Fine-tune 时使用 num_beams=2
2. 评估迁移学习效果

---

### 研究贡献

**学术价值**：
1. 发现了 HTRFlow 在瑞典历史文档上的最佳配置
2. 挑战了"beam越大越好"的常识
3. 为未来研究者节省计算资源

**实践价值**：
- Gender and Work 可直接采用 beam=2
- 预计节省 63% 处理时间（vs beam=8）
- 质量不受影响

---

### 截图
- Beam 对比结果: `screenshots/day2/beam_comparison_results.png`
- 终端完整输出: `screenshots/day2/beam_experiment_terminal.pdf`

---

### 附录：低置信度行详情

#### Beam=1 的21个低质量行
```
Line 0: 0.6551 - "Christimam" (应为 Christina)
Line 1: 0.7416 - "Norrlanden uhr" (应为 ahr)
Line 4: 0.7231 - "Geer Gers Gustaf" (多了 Gers)
[...更多错误]
```

#### Beam=2, 4, 8 的共同低质量行
```
Line 6: 0.8645 - "fl 3"
→ 这是页面标注，非正文内容
→ 低置信度合理
```

---
